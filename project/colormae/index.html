<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academia 4.3.1">
  <meta name="generator" content="Hugo 0.70.0" />

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Carlos Hinojosa">

  
  
  
    
  
  <meta name="description" content="Landing page of our ECCV 2024 Paper.">

  
  <link rel="alternate" hreflang="en-us" href="http://carloshinojosa.me/project/colormae/">

  


  

  
  
  
  <meta name="theme-color" content="#23BF53">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Open+Sans|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academia.min.21dd17c57da63b5d50cc96fce0b62689.css">

  
    
    
    
    
      
    
    
    
    <link rel="stylesheet" href="/css/academia.eb6a04338d88be94beddb66825b07e37.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-153594023-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="http://carloshinojosa.me/project/colormae/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@CarlosH_93">
  <meta property="twitter:creator" content="@CarlosH_93">
  
  <meta property="og:site_name" content="Carlos Hinojosa">
  <meta property="og:url" content="http://carloshinojosa.me/project/colormae/">
  <meta property="og:title" content="ColorMAE: Exploring data-independent masking strategies in Masked AutoEncoders | Carlos Hinojosa">
  <meta property="og:description" content="Landing page of our ECCV 2024 Paper."><meta property="og:image" content="http://carloshinojosa.me/img/icon-192.png">
  <meta property="twitter:image" content="http://carloshinojosa.me/img/icon-192.png"><meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2024-09-24T00:18:30&#43;00:00">
  
  <meta property="article:modified_time" content="2024-09-24T00:18:30&#43;00:00">
  

  


  





  <title>ColorMAE: Exploring data-independent masking strategies in Masked AutoEncoders | Carlos Hinojosa</title>

</head>


<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" role="textbox" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Carlos Hinojosa</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation"><span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#hero"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#gallery"><span>Conferences</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/resume/"><span>Resume</span></a>
        </li>

        
        

      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  
<span class="js-widget-page d-none"></span>




  







  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="introduction" class="home-section wg-new-intro-project   intro_class_colormae"  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 section-heading2 text-center">
      <h1>ColorMAE: Exploring data-independent masking strategies in Masked AutoEncoders</h1>
      <p>We design data-independent masking for MAE by filtering Noise.</p>
    </div>
    <div class="authors-container">
    
    <div class="col-12 col-sm-auto people-person">
      <a href="https://carloshinojosa.me"><img class="portrait" src="/img/user.png"></a>

      <div class="portrait-title">
        <h3><a href="https://carloshinojosa.me">Carlos Hinojosa</a></h3>
        <p></p>
      </div>
    </div>
    
    <div class="col-12 col-sm-auto people-person">
      <a href="https://sming256.github.io"><img class="portrait" src="/img/shuming.jpg"></a>

      <div class="portrait-title">
        <h3><a href="https://sming256.github.io">Shuming Liu</a></h3>
        <p></p>
      </div>
    </div>
    
    <div class="col-12 col-sm-auto people-person">
      <a href="https://www.bernardghanem.com/"><img class="portrait" src="/img/bernard.jpg"></a>

      <div class="portrait-title">
        <h3><a href="https://www.bernardghanem.com/">Bernard Ghanem</a></h3>
        <p></p>
      </div>
    </div>
    
    </div>
    <div class="col-12">
      <!-- raw HTML omitted -->
<!-- raw HTML omitted -->


  <p style="text-align:center">
    King Abdullah University of Science and Technology (KAUST), GenAI Center of Excellence
  </p>


    </div>

  <div class="btn-links project_links">
    














<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/files/ColorMAE.pdf" target="_blank" rel="noopener">
  PDF
</a>











<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/files/ColorMAE_Supp.pdf" target="_blank" rel="noopener">
  Supplementary
</a>









<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/carlosh93/ColorMAE" target="_blank" rel="noopener">
  Code
</a>










<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/files/ColorMAE_Poster.pdf" target="_blank" rel="noopener">
  Poster
</a>









  </div>

  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="abstract" class="home-section wg-blank   intro_class_colormae"  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 section-heading text-center">
      <h1>Abstract</h1>
      
    </div>
    <div class="col-12">
      





<figure class="introFig">

<img src="/files/ECCV2024ColorMAE/intro_white.png" >


</figure>



<p style="text-align: justify;">Current Data-dependent Masking approaches for MAE allow for the extraction of better feature representations but come with additional computational costs. In contrast, data-independent masking approaches do not incur additional computational costs, although they result in lower visual representations. Can we enhance MAE performance beyond random masking without relying on input data or incurring additional computational costs?</p>

<p style="text-align: justify;">We introduce <span style="background: linear-gradient(to right, #4690ec, #4bbd7a, #9d45ef, #fb4437); -webkit-background-clip: text; color: transparent;">ColorMAE</span>, a simple yet effective data-independent method which generates different binary mask patterns by filtering random noise. Drawing inspiration from color noise in image processing, we explore four types of filters to yield mask patterns with different spatial and semantic priors. <span style="background: linear-gradient(to right, #4690ec, #4bbd7a, #9d45ef, #fb4437); -webkit-background-clip: text; color: transparent;">ColorMAE</span> requires no additional learnable parameters or computational overhead in the network, yet it significantly enhances the learned representations.</p>



    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="method" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 section-heading text-center">
      <h1>Method Overview</h1>
      
    </div>
    <div class="col-12">
      





<figure>

<img src="/files/ECCV2024ColorMAE/proposed_white.png" >


</figure>



<p style="text-align: justify;">
In image processing, the concept of color noise refers to different types of noise, each characterized by a unique frequency distribution, such as predominance in the low-frequency band. Inspired by this concept, we introduce a simple yet effective data-independent method, termed <span style="background: linear-gradient(to right, #4690ec, #4bbd7a, #9d45ef, #fb4437); -webkit-background-clip: text; color: transparent;">ColorMAE</span>, which generates binary mask patterns by filtering random noise. We explore four types of filters to yield mask patterns with different spatial and semantic priors. To align with traditional terminology in image processing, we categorize the produced <i>random</i> patterns as <span style="color: #fb4437">Red</span>, <span style="color: #4690ec"> Blue</span>, <span style="color: #4bbd7a">Green</span>, and <span style="color: #9d45ef">Purple</span> noise.</p>

<h3><span style="color: #fb4437">Red Noise</span></h3>

<p style="text-align: justify;">Let $W(x, y)$ represent a random noise image, where $x$ and $y$ are spatial coordinates. We apply a blurring operation over $W$ using a Gaussian kernel $G_{\sigma}$ with standard deviation $\sigma$ to filter out the high-frequency components and accentuate low frequencies effectively. This operation transforms the random noise into red noise $N_r$ given by:</p>

<p>$$
N_r = G_\sigma * W,
$$</p>
<p>where $*$ denotes the convolution operation.</p>


<h3><span style="color: #4690ec">Blue Noise</span></h3>

<p style="text-align: justify;">To generate blue noise patterns, it is required to apply a high-pass filter over $W$. A practical approach to implementing a high-pass filter involves first applying a low-pass filter $(G_\sigma * W)$ to obtain the low-frequency content. Then, this filtered output is subtracted from the original random noise image $W$, effectively retaining the high-frequency components. The resulting blue noise $N_b$ is formally expressed as</p>

<p>$$
N_b = W - G_\sigma * W.
$$</p>


<h3><span style="color: #4bbd7a">Green Noise</span></h3>

<p style="text-align: justify;">This noise is defined as the mid-frequency component of white noise; i.e., it can be generated by applying a band-pass filter over $W$ to eliminate both high and low frequencies. Such band-pass filtering effect can be approximated by sequentially applying two Gaussian blurs: first, a weak blur is applied to $W$ to remove the highest frequency details, followed by a separate strong blur to capture the lowest frequency content of $W$. By subtracting the strongly blurred version of $W$ from the weakly blurred one, the resultant noise image retains only the mid-frequency components. Formally, the green noise $N_g$ image can be obtained as </p>

<p>$$
N_g = G_{\sigma_1} * W - G_{\sigma_2} * W,
$$</p>
<p>where $\sigma_1$ and $\sigma_2$ denote the standard deviation of the two Gaussian kernels with $\sigma_1  &lt; \sigma_2$.</p>
<p>

<h3><span style="color: #9d45ef">Purple Noise</span></h3>

<p style="text-align: justify;">Finally, in this work, we refer to purple noise as the noise that has only high and low-frequency content, i.e., does not have a middle-frequency component. We apply a band-stop filter over the random noise $W$ to produce this type of noise. Specifically, we first apply a band-pass filter to $W$ to obtain green noise and then subtract it from the input $W$, preserving only the low and high frequencies. Formally, this transformation of the noise $W$ into purple noise $N_p$ can be expressed as </p>

$$
N_p = W - (G_{\sigma_1} * W - G_{\sigma_2} * W),
$$</p>


<p style="text-align: justify;">where $\sigma_1  < \sigma_2$. Analyzing the periodogram (P) in the above Figure (column "Purple"), we can observe that this noise combines the characteristics of both red and blue noise.</p>


<h3>Mask Generation</span></h3>


<p style="text-align: justify;">In implementation, we pre-compute color noise offline and store them in GPU memory before initiating MAE pre-training. To efficiently generate the masks during pre-training, we first apply random transformations on the loaded noise tensor to get a $P$-sized square noise window for every image in the batch $B$, where $P$ is the total number of patches. Then, we select the highest values from the noise window according to the desired mask ratio. Specifically, we apply random crop, horizontal flip, and vertical flip image transformation. Note that these image transformations operate in the spatial domain; hence, the frequency properties described in the previous section are preserved. The below Algorithm shows the pseudo-code for our masking approach in PyTorch style. </p>
 
<style>
        /* CSS styles */
        .image-container {
            display: flex;
            justify-content: center;  /* Centers the image horizontally */
        }

        .image-container img {
            max-width: 100%;   /* Makes the image responsive */
            height: auto;      /* Maintains the aspect ratio */
            max-height: 800px; /* Example max height; adjust as needed */
            width: auto;       /* Ensures width adapts with height */
        }
    </style>

    <!-- HTML structure -->
    <div class="image-container">
        <img src="/files/ECCV2024ColorMAE/algorithm.png" alt="Description of image">
    </div>


    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="masks" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 section-heading text-center">
      <h1>Our Data-independent Masking Strategies</h1>
      
    </div>
    <div class="col-12">
      


<style>
        figcaption {
            text-align: justify;  /* Justify the caption text */
            font-size: 18px;      /* Optional: adjust font size */
            margin-top: 10px;     /* Optional: add space above the caption */
        }
</style>

<figure>
        <img src="/files/ECCV2024ColorMAE/main_qualitative_white.png" alt="Our Generated Masks.">
        <figcaption>Reconstruction results on ImageNet validation images from MAE pre-trained during 300 epochs with our four generated masks: <span style="color: #4690ec">Blue</span>, <span style="color: #4bbd7a">Green</span>, <span style="color: #9d45ef">Purple</span>, and <span style="color: #fb4437">Red</span>.</figcaption>
</figure>


    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="results" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 section-heading text-center">
      <h1>Experimental Results</h1>
      
    </div>
    <div class="col-12">
      

<p style="text-align: justify;">
We evaluate the performance of MAE on the downstream tasks mentioned in the previous section when we pre-train with our proposed four types of <span style="background: linear-gradient(to right, #4690ec, #4bbd7a, #9d45ef, #fb4437); -webkit-background-clip: text; color: transparent;">ColorMAE</span> masks.</p>

<style>
        figcaption {
            text-align: justify;  /* Justify the caption text */
            font-size: 18px;      /* Optional: adjust font size */
            margin-top: 10px;     /* Optional: add space above the caption */
        }
</style>

<figure>
        <img src="/files/ECCV2024ColorMAE/ablations_white.png" alt="Ablation Studies.">
        <figcaption>Downstream tasks performance after fine-tuning. MAE is pre-trained on ImageNet-1K with random masking and our proposed masking approach. We report ImageNet-1K Top-1 accuracy, ADE20K mIoU, and COCO $AP^{bbox}$ for classification, semantic segmentation, and object detection, respectively.</figcaption>
</figure>

<figure>
        <img src="/files/ECCV2024ColorMAE/comparison_white.png" alt="Comparison with state-of-the-art methods.">
        <figcaption>Comparison with state-of-the-art methods pre-trained on ImageNet-1K. The resolution of images is $224 \times 224$ for both pre-training and fine-tuning. $\dagger$ indicates our implementation, including pre-training and fine-tuning. $\ddagger$ means the results are borrowed from Chen et al. (2024). § means the results are borrowed from Wang et al. (2024).</figcaption>
</figure>



    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="analysis" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 section-heading text-center">
      <h1>Attention Analysis</h1>
      
    </div>
    <div class="col-12">
      

<p style="text-align: justify;">
In the Figure below, we show examples of self-attention maps of the [CLS] tokens averaged across the heads of the last layer, for the three different datasets. Here, we show the results for MAE pre-trained using random and our proposed <span style="color: #4bbd7a">Green</span> masking approach.
</p>

<style>
        figcaption {
            text-align: justify;  /* Justify the caption text */
            font-size: 18px;      /* Optional: adjust font size */
            margin-top: 10px;     /* Optional: add space above the caption */
        }
</style>

<figure>
        <img src="/files/ECCV2024ColorMAE/vis_attention.png" alt="Self-attention of the [CLS] tokens.">
        <figcaption>Self-attention of the [CLS] tokens averaged across the heads of the last layer in MAE pre-trained using random masking and our proposed Green masking approach (<span style="color: #4bbd7a">ColorMAE-G</span>). We show attention maps on images from Imagenet-1K (1st-3rd columns), Microsoft COCO (4th-6th columns) and ADE20K (7th-9th columns) datasets. Both MAE and <span style="color: #4bbd7a">ColorMAE-G</span> are pre-trained on ImageNet-1K for 300 epochs. Please refer to our supplementary for more visualizations of the attention maps when pre-training MAE with other <span style="background: linear-gradient(to right, #4690ec, #4bbd7a, #9d45ef, #fb4437); -webkit-background-clip: text; color: transparent;">ColorMAE</span> masks.</figcaption>
</figure>

<figure>
        <img src="/files/ECCV2024ColorMAE/vis_cam.png" alt="Class Activation Maps">
        <figcaption>Comparative visualization of Class Activation Maps (CAM) generated with EigenCAM for ViT-B. First, we perform self-supervised pre-training using standard MAE with random masking and our <span style="color: #4bbd7a">ColorMAE-G</span> on the ImageNet-1K dataset. Then, we conduct end-to-end supervised fine-tuning following the standard protocol for ImageNet classification during 100 epochs. We show CAM maps of the ViT-B pretrained with MAE (second row) and our <span style="color: #4bbd7a">ColorMAE-G</span> (third row) on images from ImageNet-1K (1st-3rd column), Microsoft COCO (4th-6th columns), and ADE20K (7th-9th columns) datasets.</figcaption>
</figure>

<p>For more results, analysis, visualizations and details, please refer to our paper and supplementary materials.</p>

    </div>
  
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="citation" class="home-section wg-blank   "  >
    <div class="container">
      


<div class="row">
  
    <div class="col-12 section-heading text-center">
      <h1>Cite this work</h1>
      
    </div>
    <div class="col-12">
      <!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<pre><code>@article{hinojosa2024colormae,
  title={ColorMAE: Exploring data-independent masking strategies in Masked AutoEncoders},
  author={Hinojosa, Carlos and Liu, Shuming and Ghanem, Bernard},
  journal={arXiv preprint arXiv:2407.13036},
  url={https://arxiv.org/pdf/2407.13036}
  year={2024}
}
</code></pre>
    </div>
  
</div>

    </div>
  </section>



      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    
    <script id="dsq-count-scr" src="//http-carloshinojosa-me.disqus.com/count.js" async></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academia.min.e4fc229c2f28284fc2dfa5b66a52b765.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">

  <div class="container">
    <div class="row">
      <div class="col-md-6">
        
        <p>
          © All right reserved by Carlos Hinojosa, 2025 &middot; 
          <a href="https://cemse.kaust.edu.sa/ai/people/person/carlos-hinojosa" target="_blank" rel="noopener">GenAI Center of Excellence</a>
        </p>
      </div>
      <div class="col-md-6">
        <ul class="list-inline network-icon text-right">
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="list-inline-item">
            <a href="https://twitter.com/CarlosH_93" target="_blank" rel="noopener" title="DM Me"><i class="fab fa-twitter" aria-hidden="true"></i></a>
          </li>
          
          
          
          
          
          
          
          
          
          
          <li class="list-inline-item">
            <a href="skype:carlos_h93?call"  title="Skype Me"><i class="fab fa-skype" aria-hidden="true"></i></a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="list-inline-item">
            <a href="https://wa.link/7hxpg4" target="_blank" rel="noopener" title="Whatsapp Me"><i class="fab fa-whatsapp" aria-hidden="true"></i></a>
          </li>
          
        </ul>
      </div>
    </div>
  </div>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
