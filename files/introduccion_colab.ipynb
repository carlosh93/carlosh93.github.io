{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Run_Reto_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MOnUXrfaDl7P"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KYvm7elVabs",
        "colab_type": "text"
      },
      "source": [
        "# Check GPU status\n",
        "\n",
        "Make surre to use : GPU runtime mode (Runtime->Change Runtime type -> python3 + GPU\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nwY1_gYVcpc",
        "colab_type": "code",
        "outputId": "867b48b6-7c66-496e-eebe-7c4276271ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "# Check nvidia and nvcc cuda compiler\n",
        "\n",
        "!nvidia-smi\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May  7 23:00:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me6ObUv4_Teh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ps -ef | grep root"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rH01wuZ_-3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill 4647"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsLpUDE54l_M",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT66Rd6yV3ib",
        "colab_type": "text"
      },
      "source": [
        "##Mount Goolge Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUCE2A_DVeMe",
        "colab_type": "code",
        "outputId": "227cf7e4-61d9-436b-b617-38013ecff606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "# link to google drive\n",
        "\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive/')\n",
        "drive.mount(\"/content/gdrive/\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDwQtkvfiYcQ",
        "colab_type": "text"
      },
      "source": [
        "**OJO** Verificar que estamos en la carpeta \n",
        "\n",
        "```\n",
        "/content/\n",
        "```\n",
        "(con el comando pwd) antes de ejecutar unrar. Esto con el objetivo de descomprimir los datos en colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpDLZZfQe1LQ",
        "colab_type": "code",
        "outputId": "9537e340-ca3e-4d0f-9f18-34c20cfb34c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SErH2-M0apgz",
        "colab_type": "text"
      },
      "source": [
        "### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75sDuU18j5lp",
        "colab_type": "code",
        "outputId": "c4a12450-4a8d-43c1-c76d-39e50287b475",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0c3d819f-ed15-4bcf-b6d5-6118d5f701ac\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0c3d819f-ed15-4bcf-b6d5-6118d5f701ac\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"carlosh93\",\"key\":\"61a2b58293b828bcb6837e0685504047\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3LaGrXBkBVP",
        "colab_type": "code",
        "outputId": "b6294c40-c999-4bee-91b0-0b24996fbb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls -lha kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 65 May  7 23:01 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU86ReFjkH8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle/\n",
        "!cp kaggle.json ~/.kaggle\n",
        "# This permissions change avoids a warning on Kaggle tool startup\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT9--vTLoZ9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VNOe6MEtbtn",
        "colab_type": "text"
      },
      "source": [
        "*Create Directories*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2Yf3cXKtDUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -R /content/sample_data/\n",
        "!mkdir /content/data\n",
        "!mkdir /content/data/train\n",
        "!mkdir /content/data/val\n",
        "!mkdir /content/data/mini_train\n",
        "!mkdir /content/data/mini_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lob1O4_6oqI",
        "colab_type": "text"
      },
      "source": [
        "**Ejecutar una de las dos opciones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcKhFPXLuGno",
        "colab_type": "text"
      },
      "source": [
        "(Opcion 1) *Run this if you want to use mini_train and mini_val*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43KrfoTgr2as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download carlosh93/reto-hdsp2 -p /content/data/mini_train -f mini_train.tfrecord\n",
        "!unzip /content/data/mini_train/mini_train.tfrecord.zip -d /content/data/mini_train/\n",
        "!rm /content/data/mini_train/mini_train.tfrecord.zip\n",
        "\n",
        "!kaggle datasets download carlosh93/reto-hdsp2 -p /content/data/mini_val -f mini_val.tfrecord\n",
        "!unzip /content/data/mini_val/mini_val.tfrecord.zip -d /content/data/mini_val/\n",
        "!rm /content/data/mini_val/mini_val.tfrecord.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg4UBJuSwzxw",
        "colab_type": "text"
      },
      "source": [
        "(Opcion 2) *Run this if you want to use full train and val datasets*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VkBRN6tvZJu",
        "colab_type": "code",
        "outputId": "dda5235b-4c0f-4c6b-99b5-22f7f1099aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "# Download Train\n",
        "\"\"\"\n",
        "!kaggle datasets download carlosh93/reto-hdsp1 -p /content/data/train -f train_split1.tfrecord\n",
        "!unzip /content/data/train/train_split1.tfrecord.zip -d /content/data/train/\n",
        "!rm /content/data/train/train_split1.tfrecord.zip\n",
        "\n",
        "!kaggle datasets download carlosh93/reto-hdsp1 -p /content/data/train -f train_split2.tfrecord\n",
        "!unzip /content/data/train/train_split2.tfrecord.zip -d /content/data/train/\n",
        "!rm /content/data/train/train_split2.tfrecord.zip\n",
        "\n",
        "!kaggle datasets download carlosh93/reto-hdsp1 -p /content/data/train -f train_split3.tfrecord\n",
        "!unzip /content/data/train/train_split3.tfrecord.zip -d /content/data/train/\n",
        "!rm /content/data/train/train_split3.tfrecord.zip\n",
        "\"\"\"\n",
        "#!kaggle datasets download carlosh93/reto-hdsp2 -p /content/data/train -f train_split4.tfrecord\n",
        "!unzip /content/data/train/train_split4.tfrecord.zip -d /content/data/train/\n",
        "!rm /content/data/train/train_split4.tfrecord.zip\n",
        "# Download Val\n",
        "!kaggle datasets download carlosh93/reto-hdsp2 -p /content/data/val -f val.tfrecord\n",
        "!unzip /content/data/val/val.tfrecord.zip -d /content/data/val/\n",
        "!rm /content/data/val/val.tfrecord.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/data/train/train_split4.tfrecord.zip\n",
            "  inflating: /content/data/train/train_split4.tfrecord  \n",
            "Downloading val.tfrecord.zip to /content/data/val\n",
            "100% 2.71G/2.71G [01:02<00:00, 24.1MB/s]\n",
            "100% 2.71G/2.71G [01:02<00:00, 46.5MB/s]\n",
            "Archive:  /content/data/val/val.tfrecord.zip\n",
            "  inflating: /content/data/val/val.tfrecord  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKpPsEzCzr9v",
        "colab_type": "text"
      },
      "source": [
        "Ahora vamos a la carpeta en donde tenemos guardado el codigo en Goole Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbxlDUyabBPM",
        "colab_type": "text"
      },
      "source": [
        "### Ejecutar Codigo en Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR604Uk1QxWF",
        "colab_type": "code",
        "outputId": "de3bcab0-66d6-43b7-d9a9-838566ef7bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd \"/content/gdrive/My Drive/Investigacion/Machine Learning/Deep Learning/Reto HDSP - CVPR\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Investigacion/Machine Learning/Deep Learning/Reto HDSP - CVPR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iYx8Z6ui0uC",
        "colab_type": "code",
        "outputId": "df2db115-cc51-43e2-a4db-1344d4c6be4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "backup_10_abril.zip  detect.py            \u001b[0m\u001b[01;34m__pycache__\u001b[0m/          \u001b[01;34mtools\u001b[0m/\n",
            "backup_28_abril.zip  load_data_Set.py     requirements.txt      train_net.py\n",
            "convert.py           \u001b[01;34mmodels\u001b[0m/              Run_Colab.ipynb\n",
            "\u001b[01;34mdataset_func\u001b[0m/        \u001b[01;34moutputs\u001b[0m/             Run_Reto_Colab.ipynb\n",
            "detect_bk.py         \u001b[01;34mpretrained_weights\u001b[0m/  \u001b[01;34mtest_imgs\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKvto2YbjNy8",
        "colab_type": "text"
      },
      "source": [
        "El archivo requirements.txt debe contener\n",
        "```\n",
        "opencv-python==4.2.0.34\n",
        "lxml\n",
        "tqdm\n",
        "matplotlib\n",
        "poppy\n",
        "```\n",
        "No es necesario instalar tensorflow ya que colab lo tiene instalado por defecto.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnNpGPb1jbLU",
        "colab_type": "code",
        "outputId": "9b9cba43-0978-4f41-9ee2-43a43b7f4541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 -m pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 34kB/s \n",
            "\u001b[?25hCollecting opencv-python==4.2.0.34\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c2/e9cf54ae5b1102020ef895866a67cb2e1aef72f16dd1fde5b5fb1495ad9c/opencv_python-4.2.0.34-cp36-cp36m-manylinux1_x86_64.whl (28.2MB)\n",
            "\u001b[K     |████████████████████████████████| 28.2MB 109kB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (4.2.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.38.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (3.2.1)\n",
            "Collecting poppy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/dc/6799b3048282b37bb86fcc6ed1aa22d7c80d3264e92441153d02001ccb5e/poppy-0.9.0.tar.gz (4.8MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8MB 39.9MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 28.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.18.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.28.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.0.8)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 36.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: astropy>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from poppy->-r requirements.txt (line 6)) (4.0.1.post1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (46.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (2.21.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Building wheels for collected packages: poppy, gast\n",
            "  Building wheel for poppy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for poppy: filename=poppy-0.9.0-cp36-none-any.whl size=223647 sha256=1cd01443304e85941bf1a4272e26c72294c38cd9d38a86ea471940b18f26c154\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/df/93/9c98958e77c7c333162da54b09d08de46c282211440193ec54\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=991f7f623d559666e5004d26ea81ce5d3f2cb18a58eece24eb3377c8fa49bcd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built poppy gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow-gpu, opencv-python, poppy\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed gast-0.2.2 opencv-python-4.2.0.34 poppy-0.9.0 tensorboard-2.1.1 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqe18MLW_bXC",
        "colab_type": "code",
        "outputId": "41919939-805c-4d64-824a-d5ef2be0f382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "!ls pretrained_weights/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t       yolov3.tf.data-00001-of-00002  yolov3.weights\n",
            "yolov3.tf.data-00000-of-00002  yolov3.tf.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF2jDIt9_gW5",
        "colab_type": "text"
      },
      "source": [
        "Si no hay nada dentro de pretrained_weights, correr la siguiente celda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhjLb3wgFeYW",
        "colab_type": "code",
        "outputId": "aab49a35-bb3a-44fa-9572-77dd1652dc0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 convert.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-20 19:19:57.430514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-20 19:20:07.585772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-20 19:20:07.649954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 19:20:07.650764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-04-20 19:20:07.650806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-20 19:20:07.650872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-20 19:20:07.650908: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-20 19:20:07.650942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-20 19:20:07.650974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-20 19:20:07.674724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-20 19:20:07.674803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-20 19:20:07.674947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 19:20:07.675842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 19:20:07.676537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-04-20 19:20:07.714813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-04-20 19:20:07.715216: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19d3800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-20 19:20:07.715252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-20 19:20:07.826850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 19:20:07.827710: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19d39c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-20 19:20:07.827749: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-04-20 19:20:07.832335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 19:20:07.833201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-04-20 19:20:07.833262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-20 19:20:07.833281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-20 19:20:07.833303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-20 19:20:07.833315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-20 19:20:07.833330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-20 19:20:07.833394: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-20 19:20:07.833416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-20 19:20:07.833540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 19:20:07.834385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 19:20:07.835058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-04-20 19:20:07.838657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-20 19:20:13.420519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-20 19:20:13.420580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-04-20 19:20:13.420592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-04-20 19:20:13.426213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 19:20:13.427091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 19:20:13.427913: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-20 19:20:13.428028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10634 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Model: \"yolov3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "yolo_darknet (Model)            ((None, None, None,  40620640    input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_0 (Model)             (None, None, None, 5 11024384    yolo_darknet[1][2]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_1 (Model)             (None, None, None, 2 2957312     yolo_conv_0[1][0]                \n",
            "                                                                 yolo_darknet[1][1]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_conv_2 (Model)             (None, None, None, 1 741376      yolo_conv_1[1][0]                \n",
            "                                                                 yolo_darknet[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_0 (Model)           (None, None, None, 3 4984063     yolo_conv_0[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_1 (Model)           (None, None, None, 3 1312511     yolo_conv_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_output_2 (Model)           (None, None, None, 3 361471      yolo_conv_2[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_0 (Lambda)           ((None, None, None,  0           yolo_output_0[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_1 (Lambda)           ((None, None, None,  0           yolo_output_1[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_boxes_2 (Lambda)           ((None, None, None,  0           yolo_output_2[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "yolo_nms (Lambda)               ((None, 100, 4), (No 0           yolo_boxes_0[0][0]               \n",
            "                                                                 yolo_boxes_0[0][1]               \n",
            "                                                                 yolo_boxes_0[0][2]               \n",
            "                                                                 yolo_boxes_1[0][0]               \n",
            "                                                                 yolo_boxes_1[0][1]               \n",
            "                                                                 yolo_boxes_1[0][2]               \n",
            "                                                                 yolo_boxes_2[0][0]               \n",
            "                                                                 yolo_boxes_2[0][1]               \n",
            "                                                                 yolo_boxes_2[0][2]               \n",
            "==================================================================================================\n",
            "Total params: 62,001,757\n",
            "Trainable params: 61,949,149\n",
            "Non-trainable params: 52,608\n",
            "__________________________________________________________________________________________________\n",
            "I0420 19:20:21.093699 139873775253376 convert.py:19] model created\n",
            "I0420 19:20:21.428460 139873775253376 utils.py:45] yolo_darknet/conv2d bn\n",
            "I0420 19:20:21.432441 139873775253376 utils.py:45] yolo_darknet/conv2d_1 bn\n",
            "I0420 19:20:21.438160 139873775253376 utils.py:45] yolo_darknet/conv2d_2 bn\n",
            "I0420 19:20:21.441792 139873775253376 utils.py:45] yolo_darknet/conv2d_3 bn\n",
            "I0420 19:20:21.606960 139873775253376 utils.py:45] yolo_darknet/conv2d_4 bn\n",
            "I0420 19:20:21.624363 139873775253376 utils.py:45] yolo_darknet/conv2d_5 bn\n",
            "I0420 19:20:21.629387 139873775253376 utils.py:45] yolo_darknet/conv2d_6 bn\n",
            "I0420 19:20:21.635551 139873775253376 utils.py:45] yolo_darknet/conv2d_7 bn\n",
            "I0420 19:20:21.640649 139873775253376 utils.py:45] yolo_darknet/conv2d_8 bn\n",
            "I0420 19:20:21.647228 139873775253376 utils.py:45] yolo_darknet/conv2d_9 bn\n",
            "I0420 19:20:21.655265 139873775253376 utils.py:45] yolo_darknet/conv2d_10 bn\n",
            "I0420 19:20:21.658947 139873775253376 utils.py:45] yolo_darknet/conv2d_11 bn\n",
            "I0420 19:20:21.664660 139873775253376 utils.py:45] yolo_darknet/conv2d_12 bn\n",
            "I0420 19:20:21.668339 139873775253376 utils.py:45] yolo_darknet/conv2d_13 bn\n",
            "I0420 19:20:21.673909 139873775253376 utils.py:45] yolo_darknet/conv2d_14 bn\n",
            "I0420 19:20:21.677855 139873775253376 utils.py:45] yolo_darknet/conv2d_15 bn\n",
            "I0420 19:20:21.683411 139873775253376 utils.py:45] yolo_darknet/conv2d_16 bn\n",
            "I0420 19:20:21.687264 139873775253376 utils.py:45] yolo_darknet/conv2d_17 bn\n",
            "I0420 19:20:21.692829 139873775253376 utils.py:45] yolo_darknet/conv2d_18 bn\n",
            "I0420 19:20:21.696422 139873775253376 utils.py:45] yolo_darknet/conv2d_19 bn\n",
            "I0420 19:20:21.852786 139873775253376 utils.py:45] yolo_darknet/conv2d_20 bn\n",
            "I0420 19:20:21.858372 139873775253376 utils.py:45] yolo_darknet/conv2d_21 bn\n",
            "I0420 19:20:21.868965 139873775253376 utils.py:45] yolo_darknet/conv2d_22 bn\n",
            "I0420 19:20:21.875047 139873775253376 utils.py:45] yolo_darknet/conv2d_23 bn\n",
            "I0420 19:20:21.884338 139873775253376 utils.py:45] yolo_darknet/conv2d_24 bn\n",
            "I0420 19:20:21.889857 139873775253376 utils.py:45] yolo_darknet/conv2d_25 bn\n",
            "I0420 19:20:21.898397 139873775253376 utils.py:45] yolo_darknet/conv2d_26 bn\n",
            "I0420 19:20:21.922319 139873775253376 utils.py:45] yolo_darknet/conv2d_27 bn\n",
            "I0420 19:20:21.929546 139873775253376 utils.py:45] yolo_darknet/conv2d_28 bn\n",
            "I0420 19:20:21.958555 139873775253376 utils.py:45] yolo_darknet/conv2d_29 bn\n",
            "I0420 19:20:21.963941 139873775253376 utils.py:45] yolo_darknet/conv2d_30 bn\n",
            "I0420 19:20:21.979253 139873775253376 utils.py:45] yolo_darknet/conv2d_31 bn\n",
            "I0420 19:20:21.983742 139873775253376 utils.py:45] yolo_darknet/conv2d_32 bn\n",
            "I0420 19:20:21.995567 139873775253376 utils.py:45] yolo_darknet/conv2d_33 bn\n",
            "I0420 19:20:22.000024 139873775253376 utils.py:45] yolo_darknet/conv2d_34 bn\n",
            "I0420 19:20:22.015039 139873775253376 utils.py:45] yolo_darknet/conv2d_35 bn\n",
            "I0420 19:20:22.020489 139873775253376 utils.py:45] yolo_darknet/conv2d_36 bn\n",
            "I0420 19:20:22.436953 139873775253376 utils.py:45] yolo_darknet/conv2d_37 bn\n",
            "I0420 19:20:22.444668 139873775253376 utils.py:45] yolo_darknet/conv2d_38 bn\n",
            "I0420 19:20:22.463722 139873775253376 utils.py:45] yolo_darknet/conv2d_39 bn\n",
            "I0420 19:20:22.471440 139873775253376 utils.py:45] yolo_darknet/conv2d_40 bn\n",
            "I0420 19:20:22.491567 139873775253376 utils.py:45] yolo_darknet/conv2d_41 bn\n",
            "I0420 19:20:22.499021 139873775253376 utils.py:45] yolo_darknet/conv2d_42 bn\n",
            "I0420 19:20:22.515621 139873775253376 utils.py:45] yolo_darknet/conv2d_43 bn\n",
            "I0420 19:20:22.835961 139873775253376 utils.py:45] yolo_darknet/conv2d_44 bn\n",
            "I0420 19:20:22.844591 139873775253376 utils.py:45] yolo_darknet/conv2d_45 bn\n",
            "I0420 19:20:22.938401 139873775253376 utils.py:45] yolo_darknet/conv2d_46 bn\n",
            "I0420 19:20:23.011521 139873775253376 utils.py:45] yolo_darknet/conv2d_47 bn\n",
            "I0420 19:20:23.258400 139873775253376 utils.py:45] yolo_darknet/conv2d_48 bn\n",
            "I0420 19:20:23.270949 139873775253376 utils.py:45] yolo_darknet/conv2d_49 bn\n",
            "I0420 19:20:23.532391 139873775253376 utils.py:45] yolo_darknet/conv2d_50 bn\n",
            "I0420 19:20:23.547052 139873775253376 utils.py:45] yolo_darknet/conv2d_51 bn\n",
            "I0420 19:20:23.611570 139873775253376 utils.py:45] yolo_conv_0/conv2d_52 bn\n",
            "I0420 19:20:23.618868 139873775253376 utils.py:45] yolo_conv_0/conv2d_53 bn\n",
            "I0420 19:20:23.841139 139873775253376 utils.py:45] yolo_conv_0/conv2d_54 bn\n",
            "I0420 19:20:23.976481 139873775253376 utils.py:45] yolo_conv_0/conv2d_55 bn\n",
            "I0420 19:20:24.153443 139873775253376 utils.py:45] yolo_conv_0/conv2d_56 bn\n",
            "I0420 19:20:24.169098 139873775253376 utils.py:45] yolo_output_0/conv2d_57 bn\n",
            "I0420 19:20:24.381349 139873775253376 utils.py:45] yolo_output_0/conv2d_58 bias\n",
            "I0420 19:20:24.410189 139873775253376 utils.py:45] yolo_conv_1/conv2d_59 bn\n",
            "I0420 19:20:24.414981 139873775253376 utils.py:45] yolo_conv_1/conv2d_60 bn\n",
            "I0420 19:20:24.420615 139873775253376 utils.py:45] yolo_conv_1/conv2d_61 bn\n",
            "I0420 19:20:24.445724 139873775253376 utils.py:45] yolo_conv_1/conv2d_62 bn\n",
            "I0420 19:20:24.456392 139873775253376 utils.py:45] yolo_conv_1/conv2d_63 bn\n",
            "I0420 19:20:24.515344 139873775253376 utils.py:45] yolo_conv_1/conv2d_64 bn\n",
            "I0420 19:20:24.519559 139873775253376 utils.py:45] yolo_output_1/conv2d_65 bn\n",
            "I0420 19:20:24.537314 139873775253376 utils.py:45] yolo_output_1/conv2d_66 bias\n",
            "I0420 19:20:24.540433 139873775253376 utils.py:45] yolo_conv_2/conv2d_67 bn\n",
            "I0420 19:20:24.543847 139873775253376 utils.py:45] yolo_conv_2/conv2d_68 bn\n",
            "I0420 19:20:24.548009 139873775253376 utils.py:45] yolo_conv_2/conv2d_69 bn\n",
            "I0420 19:20:24.556344 139873775253376 utils.py:45] yolo_conv_2/conv2d_70 bn\n",
            "I0420 19:20:24.560147 139873775253376 utils.py:45] yolo_conv_2/conv2d_71 bn\n",
            "I0420 19:20:24.566033 139873775253376 utils.py:45] yolo_conv_2/conv2d_72 bn\n",
            "I0420 19:20:24.568950 139873775253376 utils.py:45] yolo_output_2/conv2d_73 bn\n",
            "I0420 19:20:24.576086 139873775253376 utils.py:45] yolo_output_2/conv2d_74 bias\n",
            "I0420 19:20:24.578094 139873775253376 convert.py:22] weights loaded\n",
            "2020-04-20 19:20:24.647490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-20 19:20:29.446768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "I0420 19:20:31.677812 139873775253376 convert.py:26] sanity check passed\n",
            "I0420 19:20:33.627316 139873775253376 convert.py:29] weights saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_FBZ71bJw9",
        "colab_type": "code",
        "outputId": "c800f073-9f52-445d-a116-7d86ff6b7bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 train_net.py --classes=\"./dataset_func/new_voc2012.names\" --dataset=\"/content/data/train/\" --val_dataset=\"/content/data/val/\" --transfer=\"darknet\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-29 05:38:27.674155: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2020-04-29 05:38:27.674268: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2020-04-29 05:38:27.674290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2020-04-29 05:38:29.918602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-29 05:38:29.933904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 05:38:29.934928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-04-29 05:38:29.935255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-29 05:38:29.937410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-29 05:38:29.939473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-29 05:38:29.939890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-29 05:38:29.941760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-29 05:38:29.942981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-29 05:38:29.947330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-29 05:38:29.947489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 05:38:29.948408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 05:38:29.949240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2020-04-29 05:38:29.958186: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-04-29 05:38:29.964235: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-04-29 05:38:29.964542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30f8680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-29 05:38:29.964590: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-29 05:38:30.063304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 05:38:30.064435: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30f84c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-29 05:38:30.064477: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-04-29 05:38:30.064810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 05:38:30.065628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-04-29 05:38:30.065733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-29 05:38:30.065766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-29 05:38:30.065793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-29 05:38:30.065820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-29 05:38:30.065847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-29 05:38:30.065875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-29 05:38:30.065902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-29 05:38:30.066002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 05:38:30.066871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 05:38:30.067628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2020-04-29 05:38:30.067704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-29 05:38:30.069427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-29 05:38:30.069467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2020-04-29 05:38:30.069476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2020-04-29 05:38:30.069629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 05:38:30.070486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-29 05:38:30.071284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "Retrieving TFrecords from: /content/data/train/\n",
            "(416, 416, 16)\n",
            "Retrieving TFrecords from: /content/data/val/\n",
            "(416, 416, 16)\n",
            "TRANSFER LEARNING: darknet \n",
            "\n",
            "Pretrained weights loaded\n",
            "Restored from yolov3_train_last.tf\n",
            "Resumed from epoch 11\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', <tf.Tensor: shape=(1, 1, 16), dtype=float32, numpy=\n",
            "array([[[0.079  , 0.0512 , 0.03474, 0.02938, 0.03152, 0.0317 , 0.04366,\n",
            "         0.06496, 0.03928, 0.03526, 0.1716 , 0.51784, 0.5807 , 0.54862,\n",
            "         0.51948, 0.481  ]]], dtype=float32)>)\n",
            "W0429 05:39:23.685275 139867129141120 summary_ops_v2.py:1132] Model failed to serialize as JSON. Ignoring... ('Not JSON Serializable:', <tf.Tensor: shape=(1, 1, 16), dtype=float32, numpy=\n",
            "array([[[0.079  , 0.0512 , 0.03474, 0.02938, 0.03152, 0.0317 , 0.04366,\n",
            "         0.06496, 0.03928, 0.03526, 0.1716 , 0.51784, 0.5807 , 0.54862,\n",
            "         0.51948, 0.481  ]]], dtype=float32)>)\n",
            "Epoch 12/100\n",
            "2020-04-29 05:39:34.258995: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 30 of 100\n",
            "2020-04-29 05:39:44.255336: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 61 of 100\n",
            "2020-04-29 05:39:54.267238: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 93 of 100\n",
            "2020-04-29 05:39:56.357239: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:199] Shuffle buffer filled.\n",
            "2020-04-29 05:40:00.463473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-29 05:40:15.699646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-29 05:40:22.513748: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "2020-04-29 05:40:22.611529: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "2020-04-29 05:40:23.658270: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.\n",
            "2020-04-29 05:40:23.658391: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1259] Profiler found 1 GPUs\n",
            "2020-04-29 05:40:23.818917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1\n",
            "      1/Unknown - 60s 60s/step - loss: 12.5148 - yolo_output_0_loss: 1.1353 - yolo_output_1_loss: 1.1078 - yolo_output_2_loss: 0.09222020-04-29 05:40:25.832066: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1378] CUPTI activity buffer flushed\n",
            "2020-04-29 05:40:25.832129: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 6286 callback api events and 6286 activity events.\n",
            "      7/Unknown - 70s 10s/step - loss: 12.3143 - yolo_output_0_loss: 0.6962 - yolo_output_1_loss: 0.9492 - yolo_output_2_loss: 0.4906"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "islUJaxz2CKF",
        "colab_type": "text"
      },
      "source": [
        "### Limpiar archivos (Opcional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDc7r34gCrFH",
        "colab_type": "code",
        "outputId": "e12b724d-ac2d-4b5d-8fc4-b23d353cea74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "!ls outputs/checkpoints"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_epoch_info.txt\n",
            "checkpoint\n",
            "last_epoch_info.txt\n",
            "yolov3_train_best.tf.data-00000-of-00002\n",
            "yolov3_train_best.tf.data-00001-of-00002\n",
            "yolov3_train_best.tf.index\n",
            "yolov3_train_last.tf.data-00000-of-00002\n",
            "yolov3_train_last.tf.data-00001-of-00002\n",
            "yolov3_train_last.tf.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDdwk-o9HAG_",
        "colab_type": "code",
        "outputId": "d4b6b8eb-9760-42fb-cd7b-24a351eaaf0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "!rm -R outputs/logs/*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'outputs/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLA2f4Oxz6H-",
        "colab_type": "text"
      },
      "source": [
        "#Visualizar Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tCAEwl7z7hz",
        "colab_type": "code",
        "outputId": "00def677-9f97-4f05-bf2a-c79822b7d250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rkn_wrU1qZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir outputs/logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOnUXrfaDl7P",
        "colab_type": "text"
      },
      "source": [
        "#Setup SSH port forwarding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp7Nb33DDaoa",
        "colab_type": "code",
        "outputId": "17ad1a65-d0bd-4144-9cb4-c97db047cc7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "#1 - setup ssh/user \n",
        "\n",
        "\n",
        "#Generate a random root password\n",
        "import random, string\n",
        "password = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(30))\n",
        "\n",
        "\n",
        "#Setup sshd\n",
        "! apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\n",
        "\n",
        "#Set root password\n",
        "! echo root:$password | chpasswd\n",
        "! mkdir -p /var/run/sshd\n",
        "! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\n",
        "! echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\n",
        "\n",
        "print(\"username: root\")\n",
        "print(\"password: \", password)\n",
        "\n",
        "#Run sshd\n",
        "get_ipython().system_raw('/usr/sbin/sshd -D &')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Creating config file /etc/ssh/sshd_config with new version\n",
            "Creating SSH2 RSA key; this may take some time ...\n",
            "2048 SHA256:d2LIDwm4LrY08JWFGWYeXgLNFhawBnsVj09zUEMWK0g root@e6edf2db0681 (RSA)\n",
            "Creating SSH2 ECDSA key; this may take some time ...\n",
            "256 SHA256:Wb4wtkaS8jI7/eE4Mt/eTvMQ7smdrxj4uO5T1wvsInc root@e6edf2db0681 (ECDSA)\n",
            "Creating SSH2 ED25519 key; this may take some time ...\n",
            "256 SHA256:xtJo70w4e4+baY8r6D9TUhuKUmyqUuhKOUQwA18cM00 root@e6edf2db0681 (ED25519)\n",
            "Created symlink /etc/systemd/system/sshd.service → /lib/systemd/system/ssh.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/ssh.service → /lib/systemd/system/ssh.service.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "username: root\n",
            "password:  76XrH1pITccB84qZXw9oPEFoKFZLvW\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaFl2A88Ddb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2 - Download Ngrok\n",
        "\n",
        "! wget -P /content/ -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip -qq -n /content/ngrok-stable-linux-amd64.zip -d /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNfhKrJGDgsR",
        "colab_type": "code",
        "outputId": "a0ff6d91-428d-449a-e693-07a022c8f54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# 3 - setup Ngrok - authtoken\n",
        "\n",
        "#Ask token\n",
        "print(\"Get your authtoken from https://dashboard.ngrok.com/auth\")\n",
        "import getpass\n",
        "authtoken = getpass.getpass()\n",
        "\n",
        "#Create tunnel\n",
        "get_ipython().system_raw('/content/ngrok authtoken $authtoken && /content/ngrok tcp 22 &')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get your authtoken from https://dashboard.ngrok.com/auth\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-8b_OebEEHy",
        "colab_type": "text"
      },
      "source": [
        "Congratulations, you are ready to go. \n",
        "On Ngrok interface https://dashboard.ngrok.com/status you'll find the tcp address and the port \n",
        "\n",
        "connect using the following : \n",
        "\n",
        "```\n",
        "ssh root@0.tcp.ngrok.io -p [ngrok_port]\n",
        "\n",
        "> then enter the password generated previously\n",
        "\n",
        "```"
      ]
    }
  ]
}
